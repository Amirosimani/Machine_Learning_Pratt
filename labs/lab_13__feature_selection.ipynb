{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "% matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.cov()` Estimate a covariance matrix, given data and weights.\n",
    "\n",
    "Covariance indicates the level to which two variables vary together. If we examine N-dimensional samples, X = [x_1, x_2, ... x_N]^T, then the covariance matrix element C_{ij} is the covariance of x_i and x_j. The element C_{ii} is the variance of x_i.\n",
    "\n",
    "\n",
    "you can also use `pd.DataFrame.corr()` to compute pairwise correlation of columns.\n",
    "\n",
    "In probability theory and statistics, the mathematical concepts of `covariance` and `correlation` are very similar. Both describe the degree to which two random variables or sets of random variables tend to deviate from their expected values in similar ways.\n",
    "\n",
    "> Covariance is when two variables vary with each other, whereas Correlation is when the change in one variable results in the change in another variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scale(X_train)\n",
    "cov = np.cov(X_train_scaled, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8), dpi=100)\n",
    "plt.imshow(cov)\n",
    "plt.xticks(range(X.shape[1]), boston.feature_names)\n",
    "plt.yticks(range(X.shape[1]), boston.feature_names);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useful snippet to sort values of your heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "order = np.array(hierarchy.dendrogram(hierarchy.ward(cov), no_plot=True)['ivl'], dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8), dpi=100)\n",
    "plt.imshow(cov[order, :][:, order])\n",
    "plt.xticks(range(X.shape[1]), boston.feature_names[order])\n",
    "plt.yticks(range(X.shape[1]), boston.feature_names[order]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`f_regression` is a univariate linear regression tests for testing individual effect of each of many regressors. \n",
    "\n",
    "This is done in 2 steps:\n",
    "1. The correlation between each regressor and the target is computed\n",
    "2. It is converted to an F score then to a p-value.\n",
    "\n",
    "\n",
    "The F-test of overall significance indicates whether your linear regression model provides a better fit to the data than a model that contains no independent variables.\n",
    "\n",
    "An F-test is a type of statistical test that is very flexible. You can use them in a wide variety of settings.\n",
    "\n",
    "\n",
    "----\n",
    "A p-value is a measure of the probability that an observed difference could have occurred just by random chance. The lower the p-value, the greater the statistical significance of the observed difference.\n",
    "\n",
    "\n",
    "If the p-value is less than the significance level, your sample data provide sufficient evidence to conclude that your regression model fits the data better than the model with no independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "f_values, p_values = f_regression(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1)\n",
    "ax[0].set_title(\"F values\")\n",
    "ax[0].plot(f_values, 'o')\n",
    "ax[1].set_title(\"p values\")\n",
    "ax[1].plot(p_values, 'o')\n",
    "ax[1].set_yscale(\"log\")\n",
    "\n",
    "ax[1].set_xticks(range(X.shape[1]))\n",
    "ax[1].set_xticklabels(boston.feature_names, rotation=50);\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, SelectFpr\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "select = SelectKBest(k=2, score_func=f_regression)\n",
    "select.fit(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "print(select.transform(X_train).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# put it all in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "all_features = make_pipeline(StandardScaler(), RidgeCV())\n",
    "select_f = make_pipeline(StandardScaler(), \n",
    "                       SelectKBest(k=2, score_func=f_regression), \n",
    "                       RidgeCV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy with feature selection - F test:')\n",
    "np.mean(cross_val_score(select_f, X_train, y_train, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy without feature selection:')\n",
    "np.mean(cross_val_score(all_features, X_train, y_train, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more approaches for feature selection like `VarianceThreshold`, `mutual_info_regression`, and so on...\n",
    "\n",
    "#### Beware not to use a regression scoring function with a classification problem, you will get useless results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try `mutual information` and compare it with `F-Test`.\n",
    "\n",
    "**mutual information** is one of many quantities that measures how much one random variables tells us about another. It is a dimensionless quantity with (generally) units of bits, and can be thought of as the reduction in uncertainty about one random variable given knowledge of another.\n",
    "\n",
    "F-test captures only linear dependency. On the other hand, mutual information can capture any kind of dependency between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "select_mi = make_pipeline(StandardScaler(), \n",
    "                       SelectKBest(k=2, score_func=mutual_info_regression), \n",
    "                       RidgeCV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy with feature selection - mutual information:')\n",
    "np.mean(cross_val_score(select_mi, X_train, y_train, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare MI score and F values\n",
    "\n",
    "scores = mutual_info_regression(X_train, y_train)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 2))\n",
    "line_f, = plt.plot(f_values, 'o', c='r')\n",
    "plt.ylabel(\"F value\")\n",
    "ax2 = plt.twinx()\n",
    "line_s, = ax2.plot(scores, 'o', alpha=.7)\n",
    "ax2.set_ylabel(\"MI score\")\n",
    "plt.xticks(range(X.shape[1]), boston.feature_names)\n",
    "plt.legend([line_s, line_f], [\"Mutual info scores\", \"F values\"], loc=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive feature elimination\n",
    "\n",
    "recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the least important features are pruned from current set of features.That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "regressor = RidgeCV()\n",
    "rfecv = RFECV(estimator=regressor, step=1, cv=5,\n",
    "              scoring='r2')\n",
    "\n",
    "rfecv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remeber Lasso regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "X_train_scaled = scale(X_train)\n",
    "lasso = LassoCV().fit(X_train_scaled, y_train)\n",
    "print(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 2))\n",
    "line_f, = plt.plot(f_values, 'o', c='r')\n",
    "plt.ylabel(\"F value\")\n",
    "ax2 = plt.twinx()\n",
    "ax2.set_ylabel(\"lasso coefficients\")\n",
    "line_s, = ax2.plot(np.abs(lasso.coef_), 'o', alpha=.7)\n",
    "plt.xticks(range(X.shape[1]), boston.feature_names)\n",
    "plt.legend([line_s, line_f], [\"Lasso coefficients abs\", \"F values\"], loc=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select from model + Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficients in multiple linear models represent the relationship between the given feature, \n",
    "X\n",
    "i\n",
    " and the target, \n",
    "y\n",
    ", assuming that all the other features remain constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(\n",
    "    lasso.coef_,\n",
    "    columns=['Coefficients'], index=boston.feature_names\n",
    ").sort_values(by='Coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs.plot(kind='barh', figsize=(9, 7))\n",
    "plt.title('Ridge model, small regularization')\n",
    "plt.axvline(x=0, color='.5')\n",
    "plt.subplots_adjust(left=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to select the two features which are the most important. SelectFromModel() allows for setting the threshold. Only the features with the coef_ higher than the threshold will remain. Here, we want to set the threshold slightly above the third highest coef_ calculated by LassoCV() from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = np.abs(coefs['Coefficients'])\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_third = importance.argsort()[-3]\n",
    "threshold = importance[idx_third] + 0.01\n",
    "\n",
    "idx_features = (-importance).argsort()[:2]\n",
    "idx_features, threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "sfm = SelectFromModel(lasso, threshold=threshold)\n",
    "\n",
    "sfm_pipe = make_pipeline(StandardScaler(), \n",
    "                                sfm,\n",
    "                                RidgeCV()\n",
    "                        )\n",
    "sfm_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy with feature selection - SelectFromModel:')\n",
    "np.mean(cross_val_score(sfm_pipe, X_train, y_train, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate interaction features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2, interaction_only=True)\n",
    "poly.fit_transform(X).shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rfe_poly = make_pipeline(StandardScaler(),\n",
    "                              poly,\n",
    "                              RFECV(estimator=regressor, \n",
    "                                    step=1,\n",
    "                                    cv=5,\n",
    "                                    scoring='r2')\n",
    "                             )\n",
    "np.mean(cross_val_score(pipe_rfe_poly, X_train, y_train, cv=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
