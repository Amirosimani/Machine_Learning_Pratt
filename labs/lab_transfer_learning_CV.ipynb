{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd21279-0580-4a0b-9b03-4238dcc53533",
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install -c conda-forge ipywidgets\n",
    "# %jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58a7801-ff47-4b79-a484-cc70f93b5618",
   "metadata": {},
   "source": [
    "# What is Transfer Learning?\n",
    "\n",
    "In recent years, models have become increasingly larger (billions of parameters) and more and more labeled data has become avaialble. With more powerful infrastructure for holding that data and trainign the models (mainly thanks to the cloud), we have become increasingly good at training deep neural networks to learn a very accurate mapping from inputs to outputs.\n",
    "\n",
    "\n",
    "However, those models are usually trained on a specific dataset and for a specific task. In real world, you deal with messy data and new scenarios, many of which your model has not encountered during training and for which it is in turn ill-prepared to make predictions.\n",
    "\n",
    "The ability to transfer knowledge to new conditions is generally known as **transfer learning**.\n",
    "\n",
    "----\n",
    "\n",
    "Figure 1 shows a classic supervised learning scenario. You train a model for some task and domain A, assuming that labeled data for the same task and domain is provided.  On another occasion, when given data for some other task or domain B, we require again labeled data of the same task or domain that we can use to train a new model B so that we can expect it to perform well on this data.\n",
    "\n",
    "<img src=\"./img/lab_12_ml.png\">\n",
    "Figure 1: [The traditional supervised learning setup in ML](https://ruder.io/transfer-learning/)\n",
    "\n",
    "In the other hand, Transfer learning allows us to deal with these scenarios by leveraging the already existing labeled data of some related task or domain. We try to store this knowledge gained in solving the source task in the source domain and apply it to our problem of interest as can be seen in Figure 2.\n",
    "\n",
    "\n",
    "<img src=\"./img/lab_12_tf.png\">\n",
    "\n",
    "Figure 2: [Transfer learning setup](https://ruder.io/transfer-learning/)\n",
    "\n",
    "------\n",
    "\n",
    "### Steps of Transfer Learning\n",
    "\n",
    "Transfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem. Transfer learning is usually done for tasks where your dataset has too little data to train a full-scale model from scratch.\n",
    "\n",
    "For instance, features from a model that has learned to identify racoons may be useful to kick-start a model meant to identify tanukis.\n",
    "\n",
    "A common transfer learning workflow consists of:\n",
    "\n",
    "* Take layers from a previously trained model.\n",
    "* Freeze them, so as to avoid destroying any of the information they contain during future training rounds.\n",
    "* Add some new, trainable layers on top of the frozen layers. They will learn to turn the old features into predictions on a new dataset.\n",
    "* Train the new layers on your dataset.\n",
    "\n",
    "A last, optional step, is fine-tuning, which consists of unfreezing the entire model you obtained above (or part of it), and re-training it on the new data with a very low learning rate. This can potentially achieve meaningful improvements, by incrementally adapting the pretrained features to the new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5398f1e",
   "metadata": {},
   "source": [
    "# Computer Vision\n",
    "\n",
    "\n",
    "* **Image classification** attempts to identify the most significant object class in the image. [List of models for image classification on ImageNet data](https://paperswithcode.com/sota/image-classification-on-imagenet)\n",
    "* **Object Detection** models return a set of coordinates, called a bounding box, that specify an area of the input image containing an object, along with confidence value for that bounding box and a label. [List of models for object detection](https://paperswithcode.com/task/object-detection)\n",
    "* **Image Segmentation** models generate a pixel level boundary for each object. Image segmentation models classify each pixel in an image by either object type, in the case of semantic segmentation, or by individual objects, in the case of instance segmentation. [list](https://paperswithcode.com/task/semantic-segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00346f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
