{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Engines\n",
    "\n",
    "The goal of building recommendation engines includes:\n",
    "\n",
    "* **Similar item recommendations**: surfacing similar items to users. This approach generates recommendations for items that are similar to an item you specify.\n",
    "* **Personalized rankings**: a list of recommended items that are re-ranked for a specific user.\n",
    "* **New item recommendations**: Offering the right recommendations when new items are added to your catalog. This is one of the most challenging problems in building relevant recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does a recommendation engine work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the high-level idea:\n",
    "\n",
    "* recommend items to a user which are most popular among all the users\n",
    "* divide the users into multiple segments based on their preferences (user features) and recommend items to them based on the segment they belong to\n",
    "\n",
    "### Content based filtering\n",
    "\n",
    "This algorithm recommends products which are similar to the ones that a user has liked in the past.\n",
    "\n",
    "#### But what does **\"similar\"** mean in case of movies, musics, books, etc?\n",
    "\n",
    "First we need to  save all the information related to each user in a vector form (**profile vector**). This vector contains the past behavior of the user, for example the movies liked/disliked by the user and the ratings given by them.\n",
    "\n",
    "All the information related to items is stored in another vector called the **item vector**. For example, item vector contains the details of each movie, like genre, cast, director, etc.\n",
    "\n",
    "Once we collect the data abour users and items in vectors, we can do vector operations including calculating their distance.\n",
    "\n",
    "One common approach to measure similarity between vectors is **cosine similarity**. Cosine Similarity measures the cosine of the angle between two **non-zero** vectors of an inner product space. This similarity measurement is particularly concerned with orientation, rather than magnitude. \n",
    "\n",
    "![image](./img/cosine-similarity-1007790.jpeg) \n",
    "\n",
    "\n",
    "Based on the cosine value, which ranges between -1 to 1, the items are then arranged in descending order and you can use the result to recommend top-n items.\n",
    "\n",
    "##### Advantages and Disadvantages:\n",
    "\n",
    "Advantages:\n",
    "* No need for data on other users when applying to similar users.\n",
    "* Able to recommend to users with unique tastes.\n",
    "* Able to recommend new & popular items\n",
    "* Explanations for recommended items.\n",
    "\n",
    "Disadvantages:\n",
    "* Finding the appropriate feature is hard.\n",
    "* Doesn’t recommend items outside the user profile.\n",
    "    * this is due to the \"**non-zero** vectors\" condition. In other words, this alrogrithm is limited to recommending items that are of the same type. It will never recommend products which the user has not bought or liked in the past. So if a user has watched or liked only action movies in the past, the system will recommend only action movies. It’s a very narrow way of building an engine.\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering\n",
    "\n",
    "The collaborative filtering algorithm uses “User Behavior” for recommending items. This is one of the most commonly used algorithms in the industry as it is not dependent on any additional information. Collaborative filtering is based on the idea that similar people (based on the data) generally tend to like similar things. \n",
    "\n",
    "\n",
    "* User-User collaborative filtering: This algorithm first finds the similarity score between users. Based on this similarity score, it then picks out the most similar users and recommends products which these similar users have liked or bought previously.\n",
    "\n",
    "![image](https://miro.medium.com/max/720/0*o0zVW2O6Rv-LI5Mu.png) \n",
    "source: https://miro.medium.com/max/720/0*o0zVW2O6Rv-LI5Mu.png\n",
    "\n",
    "\n",
    "* Item-Item collaborative filtering: In this algorithm, we compute the similarity between each pair of items. Based on that, we will recommend similar movies which are liked by the users in the past.\n",
    "\n",
    "* How do you determine which users or items are similar to one another?\n",
    "* Given that you know which users are similar, how do you determine the rating that a user would give to an item based on the ratings of similar users?\n",
    "* How do you measure the accuracy of the ratings you calculate?\n",
    "\n",
    "\n",
    "no single answer!Collaborative filtering is a family of algorithms where there are multiple ways to find similar users or items and multiple ways to calculate rating based on ratings of similar users. Depending on the choices you make, you end up with a type of collaborative filtering approach. \n",
    "\n",
    "\n",
    "##### Advantages and Disadvantages:\n",
    "\n",
    "Advantages:\n",
    "* No need for the domain knowledge because embedding are learned automatically.\n",
    "\n",
    "Disadvantages:\n",
    "* Hard to add any new features that may improve quality of model\n",
    "* Cannot handle new items/users. It is called a **Cold Start**.\n",
    "    * One possible solution could be to recommend the best selling products, i.e. the products which are high in demand. Another possible solution could be to recommend the products which would bring the maximum profit to the business.\n",
    "* This algorithm is quite time consuming as it involves calculating the similarity for each user/items and then calculating prediction for each similarity score. \n",
    "   * One way of handling this problem is to select only a few users/items instead of all to make predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie recommendation using MovieLens\n",
    "\n",
    "https://grouplens.org/datasets/movielens/\n",
    "\n",
    "Small: 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users. Last updated 9/2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "df_ratings = pd.read_csv('./data/ml-latest-small/ratings.csv')\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_ratings, x=\"rating\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv(\"./data/ml-latest-small/movies.csv\")\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_ratings, df_movies, on=\"movieId\", how=\"left\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is a collection of ratings by a number of users for different movies. Let’s find out the average rating for each and every movie in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_ratings = pd.DataFrame(df.groupby('title')['rating'].mean())\n",
    "df_avg_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the rating of a movie is proportional to the total number of ratings it has. Therefore, we will also consider the total ratings cast for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_ratings['total_ratings'] = pd.DataFrame(df.groupby('title')['rating'].count())\n",
    "df_avg_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pivot the tale to get user-movie matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_mat = df.pivot_table(index='userId',columns='title',values='rating')\n",
    "user_movie_mat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_mat[user_movie_mat.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that alot of them are NaN. usually with recommendation systems, we are dealing with highly sparse data since not every user has seen and rated all the movies.\n",
    "with larger datasets, you mighy run into overflow and wasted memory. one solution is to work with scipy.sparse_matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a few approaches to build CF recommendation systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a movie before 2019\n",
    "target_movie = \"toy story\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies[df_movies[\"title\"].str.lower().str.contains(target_movie)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_movie = \"Toy Story (1995)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_corr = user_movie_mat.corrwith(user_movie_mat[target_movie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_corr = target_corr.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_corr = target_corr.reset_index()\n",
    "target_corr.columns = [\"title\", \"corr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_corr = pd.merge(target_corr, df_avg_ratings, on=\"title\")\n",
    "target_corr = target_corr.sort_values(by='corr', ascending=False)\n",
    "target_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_corr[target_corr['total_ratings']>100].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter \n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.neighbors import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remember here I want to find similar movies...so have to transpose user_movie_mat to make it easier to work with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN can be very sensitive to the scale of data as it relies on computing the distances.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_mat = user_movie_mat.T\n",
    "knn_mat = knn_mat.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_mat.iloc[:,:] = Normalizer().fit_transform(knn_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(metric='cosine', algorithm='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(knn_mat)\n",
    "\n",
    "distances, indices = knn.kneighbors(knn_mat, n_neighbors=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index for the target movie\n",
    "index_for_movie = knn_mat.index.tolist().index(target_movie)\n",
    "\n",
    "# find the indices for the similar movies\n",
    "sim_movies = indices[index_for_movie].tolist()\n",
    "sim_movies.pop(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(itemgetter(*sim_movies)(knn_mat.index.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = cosine_similarity(knn_mat, knn_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cos = pd.DataFrame(dist_matrix)\n",
    "df_cos.columns = user_movie_mat.columns\n",
    "df_cos.index = user_movie_mat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cos = pd.merge(df_cos[target_movie], df_avg_ratings, on=\"title\")\n",
    "\n",
    "target_cos.columns = [\"similarity\", \"rating\", \"total_ratings\"]\n",
    "target_cos = target_cos.sort_values(by='similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cos[target_cos['total_ratings']>100].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
