{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd21279-0580-4a0b-9b03-4238dcc53533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install -c conda-forge ipywidgets\n",
    "# %jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "!pip install pydot graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58a7801-ff47-4b79-a484-cc70f93b5618",
   "metadata": {},
   "source": [
    "# What is Transfer Learning?\n",
    "\n",
    "With more powerful infrastructure for holding that data and training the models (mainly thanks to the cloud), we have become increasingly good at training deep neural networks to learn a very accurate mapping from inputs to outputs.\n",
    "\n",
    "In recent years, models have become increasingly larger (billions of parameters) and more and more labeled data has become available.In recent years, models have become increasingly larger (billions of parameters) and more and more labeled data has become available.\n",
    "\n",
    "However, those models are usually trained on a specific dataset and for a specific task. In real world, you deal with messy data and new scenarios, many of which your model has not encountered during training and for which it is in turn ill-prepared to make predictions.\n",
    "\n",
    "The ability to transfer knowledge to new conditions is generally known as **transfer learning**.\n",
    "\n",
    "----\n",
    "\n",
    "Figure 1 shows a classic supervised learning scenario. You train a model for some task and domain A, assuming that labeled data for the same task and domain is provided.  On another occasion, when given data for some other task or domain B, we require again labeled data of the same task or domain that we can use to train a new model B so that we can expect it to perform well on this data.\n",
    "\n",
    "<img src=\"./img/lab_12_ml.png\">\n",
    "\n",
    "Figure 1: [The traditional supervised learning setup in ML](https://ruder.io/transfer-learning/)\n",
    "\n",
    "In the other hand, Transfer learning allows us to deal with these scenarios by leveraging the already existing labeled data of some related task or domain. We try to store this knowledge gained in solving the source task in the source domain and apply it to our problem of interest as can be seen in Figure 2.\n",
    "\n",
    "\n",
    "<img src=\"./img/lab_12_tf.png\">\n",
    "\n",
    "\n",
    "Figure 2: [Transfer learning setup](https://ruder.io/transfer-learning/)\n",
    "\n",
    "------\n",
    "\n",
    "### Steps of Transfer Learning\n",
    "\n",
    "Transfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem. Transfer learning is usually done for tasks where your dataset has too little data to train a full-scale model from scratch.\n",
    "\n",
    "For instance, features from a model that has learned to identify racoons may be useful to kick-start a model meant to identify possoms.\n",
    "\n",
    "A common transfer learning workflow consists of:\n",
    "\n",
    "* Take layers from a previously trained model.\n",
    "* Freeze them, so as to avoid destroying any of the information they contain during future training rounds.\n",
    "* Add some new, trainable layers on top of the frozen layers. They will learn to turn the old features into predictions on a new dataset.\n",
    "* Train the new layers on your dataset.\n",
    "\n",
    "A last, optional step, is fine-tuning, which consists of unfreezing the entire model you obtained above (or part of it), and re-training it on the new data with a very low learning rate. This can potentially achieve meaningful improvements, by incrementally adapting the pretrained features to the new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed276ae",
   "metadata": {},
   "source": [
    "## Benchmarks for Computer Vision\n",
    "\n",
    "\n",
    "* **Image classification** attempts to identify the most significant object class in the image. [List of models for image classification on ImageNet data](https://paperswithcode.com/sota/image-classification-on-imagenet)\n",
    "* **Object Detection** models return a set of coordinates, called a bounding box, that specify an area of the input image containing an object, along with confidence value for that bounding box and a label. [List of models for object detection](https://paperswithcode.com/task/object-detection)\n",
    "* **Image Segmentation** models generate a pixel level boundary for each object. Image segmentation models classify each pixel in an image by either object type, in the case of semantic segmentation, or by individual objects, in the case of instance segmentation. [list](https://paperswithcode.com/task/semantic-segmentation)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f69ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to download data and extract\n",
    "def get_data_extract():\n",
    "  if \"./data/food-101\" in os.listdir():\n",
    "    print(\"Dataset already exists\")\n",
    "  else:\n",
    "    print(\"Downloading the data...\")\n",
    "    !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz \n",
    "    print(\"Dataset downloaded!\")\n",
    "    print(\"Extracting data..\")\n",
    "    !tar xzvf food-101.tar.gz\n",
    "    print(\"Extraction done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b318d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 224\n",
    "width = 224\n",
    "channels = 3\n",
    "batch_size = 64\n",
    "img_shape = (height, width, channels)\n",
    "img_size = (height, width)\n",
    "\n",
    "data_dir = \"./food-101/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.preprocessing.image_dataset_from_directory(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d03041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an ImageDataGenerator and doing Image Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6313222",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size = img_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'training')\n",
    "\n",
    "val_data = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size = img_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d63b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(train_data.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c2e754",
   "metadata": {},
   "source": [
    "Now let's check papers with code to see the best performing model for Food-101:\n",
    "\n",
    "https://paperswithcode.com/sota/fine-grained-image-classification-on-food-101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42293c09",
   "metadata": {},
   "source": [
    "Efficient Net B0: This model takes input images of shape (224, 224, 3)and the input data should range [0, 255]. Normalization is included as part of the model.\n",
    "\n",
    "\n",
    "Replacing the top layer with custom layers allows using EfficientNet as a feature extractor in a transfer learning workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055359d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85087564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes, input_shape=img_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = inputs\n",
    "    model = EfficientNetB0(include_top=False, \n",
    "                           input_tensor=x, \n",
    "                           weights=\"imagenet\")\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    top_dropout_rate = 0.2\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c6201",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d2758",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f42896",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "hist = model.fit(train_data,\n",
    "                 epochs=epochs, \n",
    "                 validation_data=val_data,\n",
    "                 verbose=1\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825aa83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ed7ab5",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "\n",
    "The second step is to unfreeze a number of layers and fit the model using smaller learning rate. In this example we show unfreezing 5 layers, but depending on specific dataset it may be desireble to  unfreeze all or a fraction of layers.\n",
    "\n",
    "On the other hand, when we use pretrained weights on a dataset that is more different from ImageNet, this fine-tuning step can be crucial as the feature extractor also needs to be adjusted by a considerable amount. In such a case the convergence may take more than 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c918bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_model(model, num_layers=5):\n",
    "    # We unfreeze the top 5 layers while leaving BatchNorm layers frozen\n",
    "    for layer in model.layers[-num_layers:]:\n",
    "        if not isinstance(layer, layers.BatchNormalization):\n",
    "            print(layer)\n",
    "            layer.trainable = True\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bcca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b610adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint callback to save model for later use\n",
    "checkpoint_path = \"./data/checkpoints/\"\n",
    "!mkdir -p $checkpoint_path\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                         save_weights_only=True, # save only the model weights\n",
    "                                                         monitor=\"val_accuracy\",\n",
    "                                                         save_best_only=True\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ft = model.fit(train_data,\n",
    "                 epochs=epochs, \n",
    "                 validation_data=val_data,\n",
    "                 verbose=1,\n",
    "                 callbacks=[checkpoint_callback]\n",
    "                )\n",
    "\n",
    "plot_hist(hist_ft)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
